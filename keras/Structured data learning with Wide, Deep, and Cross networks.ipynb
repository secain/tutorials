{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The dataset\n",
    "This example uses the Covertype dataset from the UCI Machine Learning Repository. The task is to predict forest cover type from cartographic variables. The dataset includes 506,011 instances with 12 input features: 10 numerical features and 2 categorical features. Each instance is categorized into 1 of 7 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (581012, 55)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2596</td>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>510</td>\n",
       "      <td>221</td>\n",
       "      <td>232</td>\n",
       "      <td>148</td>\n",
       "      <td>6279</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2590</td>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "      <td>212</td>\n",
       "      <td>-6</td>\n",
       "      <td>390</td>\n",
       "      <td>220</td>\n",
       "      <td>235</td>\n",
       "      <td>151</td>\n",
       "      <td>6225</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2804</td>\n",
       "      <td>139</td>\n",
       "      <td>9</td>\n",
       "      <td>268</td>\n",
       "      <td>65</td>\n",
       "      <td>3180</td>\n",
       "      <td>234</td>\n",
       "      <td>238</td>\n",
       "      <td>135</td>\n",
       "      <td>6121</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2785</td>\n",
       "      <td>155</td>\n",
       "      <td>18</td>\n",
       "      <td>242</td>\n",
       "      <td>118</td>\n",
       "      <td>3090</td>\n",
       "      <td>238</td>\n",
       "      <td>238</td>\n",
       "      <td>122</td>\n",
       "      <td>6211</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2595</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>153</td>\n",
       "      <td>-1</td>\n",
       "      <td>391</td>\n",
       "      <td>220</td>\n",
       "      <td>234</td>\n",
       "      <td>150</td>\n",
       "      <td>6172</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1   2    3    4     5    6    7    8     9   ...  45  46  47  48  \\\n",
       "0  2596   51   3  258    0   510  221  232  148  6279  ...   0   0   0   0   \n",
       "1  2590   56   2  212   -6   390  220  235  151  6225  ...   0   0   0   0   \n",
       "2  2804  139   9  268   65  3180  234  238  135  6121  ...   0   0   0   0   \n",
       "3  2785  155  18  242  118  3090  238  238  122  6211  ...   0   0   0   0   \n",
       "4  2595   45   2  153   -1   391  220  234  150  6172  ...   0   0   0   0   \n",
       "\n",
       "   49  50  51  52  53  54  \n",
       "0   0   0   0   0   0   5  \n",
       "1   0   0   0   0   0   5  \n",
       "2   0   0   0   0   0   2  \n",
       "3   0   0   0   0   0   2  \n",
       "4   0   0   0   0   0   5  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_url = (\n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/covtype/covtype.data.gz\"\n",
    ")\n",
    "raw_data = pd.read_csv(data_url, header=None)\n",
    "print(f\"Dataset shape: {raw_data.shape}\")\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (581012, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Elevation</th>\n",
       "      <td>2596</td>\n",
       "      <td>2590</td>\n",
       "      <td>2804</td>\n",
       "      <td>2785</td>\n",
       "      <td>2595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aspect</th>\n",
       "      <td>51</td>\n",
       "      <td>56</td>\n",
       "      <td>139</td>\n",
       "      <td>155</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Slope</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Horizontal_Distance_To_Hydrology</th>\n",
       "      <td>258</td>\n",
       "      <td>212</td>\n",
       "      <td>268</td>\n",
       "      <td>242</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vertical_Distance_To_Hydrology</th>\n",
       "      <td>0</td>\n",
       "      <td>-6</td>\n",
       "      <td>65</td>\n",
       "      <td>118</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Horizontal_Distance_To_Roadways</th>\n",
       "      <td>510</td>\n",
       "      <td>390</td>\n",
       "      <td>3180</td>\n",
       "      <td>3090</td>\n",
       "      <td>391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hillshade_9am</th>\n",
       "      <td>221</td>\n",
       "      <td>220</td>\n",
       "      <td>234</td>\n",
       "      <td>238</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hillshade_Noon</th>\n",
       "      <td>232</td>\n",
       "      <td>235</td>\n",
       "      <td>238</td>\n",
       "      <td>238</td>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hillshade_3pm</th>\n",
       "      <td>148</td>\n",
       "      <td>151</td>\n",
       "      <td>135</td>\n",
       "      <td>122</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Horizontal_Distance_To_Fire_Points</th>\n",
       "      <td>6279</td>\n",
       "      <td>6225</td>\n",
       "      <td>6121</td>\n",
       "      <td>6211</td>\n",
       "      <td>6172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wilderness_Area</th>\n",
       "      <td>area_type_1</td>\n",
       "      <td>area_type_1</td>\n",
       "      <td>area_type_1</td>\n",
       "      <td>area_type_1</td>\n",
       "      <td>area_type_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type</th>\n",
       "      <td>soil_type_29</td>\n",
       "      <td>soil_type_29</td>\n",
       "      <td>soil_type_12</td>\n",
       "      <td>soil_type_30</td>\n",
       "      <td>soil_type_29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cover_Type</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               0             1             2  \\\n",
       "Elevation                                   2596          2590          2804   \n",
       "Aspect                                        51            56           139   \n",
       "Slope                                          3             2             9   \n",
       "Horizontal_Distance_To_Hydrology             258           212           268   \n",
       "Vertical_Distance_To_Hydrology                 0            -6            65   \n",
       "Horizontal_Distance_To_Roadways              510           390          3180   \n",
       "Hillshade_9am                                221           220           234   \n",
       "Hillshade_Noon                               232           235           238   \n",
       "Hillshade_3pm                                148           151           135   \n",
       "Horizontal_Distance_To_Fire_Points          6279          6225          6121   \n",
       "Wilderness_Area                      area_type_1   area_type_1   area_type_1   \n",
       "Soil_Type                           soil_type_29  soil_type_29  soil_type_12   \n",
       "Cover_Type                                     4             4             1   \n",
       "\n",
       "                                               3             4  \n",
       "Elevation                                   2785          2595  \n",
       "Aspect                                       155            45  \n",
       "Slope                                         18             2  \n",
       "Horizontal_Distance_To_Hydrology             242           153  \n",
       "Vertical_Distance_To_Hydrology               118            -1  \n",
       "Horizontal_Distance_To_Roadways             3090           391  \n",
       "Hillshade_9am                                238           220  \n",
       "Hillshade_Noon                               238           234  \n",
       "Hillshade_3pm                                122           150  \n",
       "Horizontal_Distance_To_Fire_Points          6211          6172  \n",
       "Wilderness_Area                      area_type_1   area_type_1  \n",
       "Soil_Type                           soil_type_30  soil_type_29  \n",
       "Cover_Type                                     1             4  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soil_type_values = [f\"soil_type_{idx+1}\" for idx in range(40)]\n",
    "wilderness_area_values = [f\"area_type_{idx+1}\" for idx in range(4)]\n",
    "\n",
    "soil_type = raw_data.loc[:, 14:53].apply(\n",
    "    lambda x: soil_type_values[0::1][x.to_numpy().nonzero()[0][0]], axis=1\n",
    ")\n",
    "wilderness_area = raw_data.loc[:, 10:13].apply(\n",
    "    lambda x: wilderness_area_values[0::1][x.to_numpy().nonzero()[0][0]], axis=1\n",
    ")\n",
    "\n",
    "CSV_HEADER = [\n",
    "    \"Elevation\",\n",
    "    \"Aspect\",\n",
    "    \"Slope\",\n",
    "    \"Horizontal_Distance_To_Hydrology\",\n",
    "    \"Vertical_Distance_To_Hydrology\",\n",
    "    \"Horizontal_Distance_To_Roadways\",\n",
    "    \"Hillshade_9am\",\n",
    "    \"Hillshade_Noon\",\n",
    "    \"Hillshade_3pm\",\n",
    "    \"Horizontal_Distance_To_Fire_Points\",\n",
    "    \"Wilderness_Area\",\n",
    "    \"Soil_Type\",\n",
    "    \"Cover_Type\",\n",
    "]\n",
    "\n",
    "data = pd.concat(\n",
    "    [raw_data.loc[:, 0:9], wilderness_area, soil_type, raw_data.loc[:, 54]],\n",
    "    axis=1,\n",
    "    ignore_index=True,\n",
    ")\n",
    "data.columns = CSV_HEADER\n",
    "\n",
    "# Convert the target label indices into a range from 0 to 6 (there are 7 labels in total).\n",
    "data[\"Cover_Type\"] = data[\"Cover_Type\"] - 1\n",
    "\n",
    "print(f\"Dataset shape: {data.shape}\")\n",
    "data.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train split size: 493796\n",
      "Test split size: 87216\n"
     ]
    }
   ],
   "source": [
    "train_splits = []\n",
    "test_splits = []\n",
    "\n",
    "for _, group_data in data.groupby(\"Cover_Type\"):\n",
    "    random_selection = np.random.rand(len(group_data.index)) <= 0.85\n",
    "    train_splits.append(group_data[random_selection])\n",
    "    test_splits.append(group_data[~random_selection])\n",
    "\n",
    "train_data = pd.concat(train_splits).sample(frac=1).reset_index(drop=True)\n",
    "test_data = pd.concat(test_splits).sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "print(f\"Train split size: {len(train_data.index)}\")\n",
    "print(f\"Test split size: {len(test_data.index)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_file = \"train_data.csv\"\n",
    "test_data_file = \"test_data.csv\"\n",
    "\n",
    "train_data.to_csv(train_data_file, index=False)\n",
    "test_data.to_csv(test_data_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define dataset metadata\n",
    "Here, we define the metadata of the dataset that will be useful for reading and parsing the data into input features, and encoding the input features with respect to their types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_FEATURE_NAME = \"Cover_Type\"\n",
    "\n",
    "TARGET_FEATURE_LABELS = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\"]\n",
    "\n",
    "NUMERIC_FEATURE_NAMES = [\n",
    "    \"Aspect\",\n",
    "    \"Elevation\",\n",
    "    \"Hillshade_3pm\",\n",
    "    \"Hillshade_9am\",\n",
    "    \"Hillshade_Noon\",\n",
    "    \"Horizontal_Distance_To_Fire_Points\",\n",
    "    \"Horizontal_Distance_To_Hydrology\",\n",
    "    \"Horizontal_Distance_To_Roadways\",\n",
    "    \"Slope\",\n",
    "    \"Vertical_Distance_To_Hydrology\",\n",
    "]\n",
    "\n",
    "CATEGORICAL_FEATURES_WITH_VOCABULARY = {\n",
    "    \"Soil_Type\": list(data[\"Soil_Type\"].unique()),\n",
    "    \"Wilderness_Area\": list(data[\"Wilderness_Area\"].unique()),\n",
    "}\n",
    "\n",
    "CATEGORICAL_FEATURE_NAMES = list(CATEGORICAL_FEATURES_WITH_VOCABULARY.keys())\n",
    "\n",
    "FEATURE_NAMES = NUMERIC_FEATURE_NAMES + CATEGORICAL_FEATURE_NAMES\n",
    "\n",
    "# 控制读取的CSV数据类型\n",
    "COLUMN_DEFAULTS = [\n",
    "    [0] if feature_name in NUMERIC_FEATURE_NAMES + [TARGET_FEATURE_NAME] else [\"NA\"]\n",
    "    for feature_name in CSV_HEADER\n",
    "]\n",
    "\n",
    "NUM_CLASSES = len(TARGET_FEATURE_LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment setup\n",
    "Next, let's define an input function that reads and parses the file, then converts features and labels into a `tf.data.Dataset` for training or evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_from_csv(csv_file_path, batch_size, shuffle=False):\n",
    "\n",
    "    dataset = tf.data.experimental.make_csv_dataset(\n",
    "        csv_file_path,\n",
    "        batch_size=batch_size,\n",
    "        column_names=CSV_HEADER,\n",
    "        column_defaults=COLUMN_DEFAULTS,\n",
    "        label_name=TARGET_FEATURE_NAME,\n",
    "        num_epochs=1,\n",
    "        header=True,\n",
    "        shuffle=shuffle,\n",
    "    )\n",
    "    return dataset.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we configure the parameters and implement the procedure for running a training and evaluation experiment given a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "dropout_rate = 0.1\n",
    "batch_size = 265\n",
    "num_epochs = 50\n",
    "\n",
    "hidden_units = [32, 32]\n",
    "\n",
    "def run_experiment(model):\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "        metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    "    )\n",
    "\n",
    "    train_dataset = get_dataset_from_csv(train_data_file, batch_size, shuffle=True)\n",
    "\n",
    "    test_dataset = get_dataset_from_csv(test_data_file, batch_size)\n",
    "\n",
    "    print(\"Start training the model...\")\n",
    "    history = model.fit(train_dataset, epochs=num_epochs)\n",
    "    print(\"Model training finished\")\n",
    "\n",
    "    _, accuracy = model.evaluate(test_dataset, verbose=0)\n",
    "\n",
    "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model inputs\n",
    "Now, define the inputs for the models as a dictionary, where the key is the feature name, and the value is a `keras.layers`.Input tensor with the corresponding feature shape and data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_inputs():\n",
    "    inputs = {}\n",
    "    for feature_name in FEATURE_NAMES:\n",
    "        if feature_name in NUMERIC_FEATURE_NAMES:\n",
    "            inputs[feature_name] = layers.Input(\n",
    "                name=feature_name, shape=(), dtype=tf.float32\n",
    "            )\n",
    "        else:\n",
    "            inputs[feature_name] = layers.Input(\n",
    "                name=feature_name, shape=(), dtype=tf.string\n",
    "            )\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode features\n",
    "We create two representations of our input features: sparse and dense: 1. In the sparse representation, the categorical features are encoded with one-hot encoding using the `CategoryEncoding` layer. This representation can be useful for the model to memorize particular feature values to make certain predictions. 2. In the dense representation, the categorical features are encoded with low-dimensional embeddings using the `Embedding` layer. This representation helps the model to generalize well to unseen feature combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers.experimental.preprocessing import CategoryEncoding\n",
    "from tensorflow.keras.layers.experimental.preprocessing import StringLookup\n",
    "\n",
    "\n",
    "def encode_inputs(inputs, use_embedding=False):\n",
    "    encoded_features = []\n",
    "    for feature_name in inputs:\n",
    "        if feature_name in CATEGORICAL_FEATURE_NAMES:\n",
    "            vocabulary = CATEGORICAL_FEATURES_WITH_VOCABULARY[feature_name]\n",
    "            # Create a lookup to convert string values to an integer indices.\n",
    "            # Since we are not using a mask token nor expecting any out of vocabulary\n",
    "            # (oov) token, we set mask_token to None and  num_oov_indices to 0.\n",
    "            index = StringLookup(\n",
    "                vocabulary=vocabulary, mask_token=None, num_oov_indices=0\n",
    "            )\n",
    "            # Convert the string input values into integer indices.\n",
    "            value_index = index(inputs[feature_name])\n",
    "            if use_embedding:\n",
    "                embedding_dims = int(math.sqrt(len(vocabulary)))\n",
    "                # Create an embedding layer with the specified dimensions.\n",
    "                embedding_ecoder = layers.Embedding(\n",
    "                    input_dim=len(vocabulary), output_dim=embedding_dims\n",
    "                )\n",
    "                # Convert the index values to embedding representations.\n",
    "                encoded_feature = embedding_ecoder(value_index)\n",
    "            else:\n",
    "                # Create a one-hot encoder.\n",
    "                onehot_encoder = CategoryEncoding(output_mode=\"binary\")\n",
    "                onehot_encoder.adapt(index(vocabulary))\n",
    "                # Convert the index values to a one-hot representation.\n",
    "                encoded_feature = onehot_encoder(value_index)\n",
    "        else:\n",
    "            # Use the numerical features as-is.\n",
    "            encoded_feature = tf.expand_dims(inputs[feature_name], -1)\n",
    "\n",
    "        encoded_features.append(encoded_feature)\n",
    "\n",
    "    all_features = layers.concatenate(encoded_features)\n",
    "    return all_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1: a baseline model\n",
    "In the first experiment, let's create a multi-layer feed-forward network, where the categorical features are one-hot encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_baseline_model():\n",
    "    inputs = create_model_inputs()\n",
    "    features = encode_inputs(inputs)\n",
    "\n",
    "    for units in hidden_units:\n",
    "        features = layers.Dense(units)(features)\n",
    "        features = layers.BatchNormalization()(features)\n",
    "        features = layers.ReLU()(features)\n",
    "        features = layers.Dropout(dropout_rate)(features)\n",
    "\n",
    "    outputs = layers.Dense(units=NUM_CLASSES, activation=\"softmax\")(features)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "baseline_model = create_baseline_model()\n",
    "keras.utils.plot_model(baseline_model, show_shapes=True, rankdir=\"LR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training the model...\n",
      "Epoch 1/50\n",
      "1864/1864 [==============================] - 22s 11ms/step - loss: 0.9334 - sparse_categorical_accuracy: 0.6318\n",
      "Epoch 2/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.6776 - sparse_categorical_accuracy: 0.7083\n",
      "Epoch 3/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.6496 - sparse_categorical_accuracy: 0.7196\n",
      "Epoch 4/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.6293 - sparse_categorical_accuracy: 0.7277\n",
      "Epoch 5/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.6134 - sparse_categorical_accuracy: 0.7367\n",
      "Epoch 6/50\n",
      "1864/1864 [==============================] - 12s 6ms/step - loss: 0.6050 - sparse_categorical_accuracy: 0.7410\n",
      "Epoch 7/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.5990 - sparse_categorical_accuracy: 0.7437\n",
      "Epoch 8/50\n",
      "1864/1864 [==============================] - 12s 6ms/step - loss: 0.5924 - sparse_categorical_accuracy: 0.7468\n",
      "Epoch 9/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.5877 - sparse_categorical_accuracy: 0.7488\n",
      "Epoch 10/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.5828 - sparse_categorical_accuracy: 0.7507\n",
      "Epoch 11/50\n",
      "1864/1864 [==============================] - 12s 6ms/step - loss: 0.5798 - sparse_categorical_accuracy: 0.7520\n",
      "Epoch 12/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.5756 - sparse_categorical_accuracy: 0.7541\n",
      "Epoch 13/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.5731 - sparse_categorical_accuracy: 0.7553\n",
      "Epoch 14/50\n",
      "1864/1864 [==============================] - 12s 6ms/step - loss: 0.5708 - sparse_categorical_accuracy: 0.7562\n",
      "Epoch 15/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.5670 - sparse_categorical_accuracy: 0.7586\n",
      "Epoch 16/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.5651 - sparse_categorical_accuracy: 0.7580\n",
      "Epoch 17/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.5632 - sparse_categorical_accuracy: 0.7586\n",
      "Epoch 18/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.5607 - sparse_categorical_accuracy: 0.7591\n",
      "Epoch 19/50\n",
      "1864/1864 [==============================] - 12s 6ms/step - loss: 0.5585 - sparse_categorical_accuracy: 0.7604\n",
      "Epoch 20/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.5573 - sparse_categorical_accuracy: 0.7611\n",
      "Epoch 21/50\n",
      "1864/1864 [==============================] - 12s 6ms/step - loss: 0.5568 - sparse_categorical_accuracy: 0.7616\n",
      "Epoch 22/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.5544 - sparse_categorical_accuracy: 0.7624\n",
      "Epoch 23/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.5526 - sparse_categorical_accuracy: 0.7630\n",
      "Epoch 24/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.5519 - sparse_categorical_accuracy: 0.7638\n",
      "Epoch 25/50\n",
      "1864/1864 [==============================] - 12s 6ms/step - loss: 0.5504 - sparse_categorical_accuracy: 0.7649\n",
      "Epoch 26/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.5488 - sparse_categorical_accuracy: 0.7656\n",
      "Epoch 27/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.5499 - sparse_categorical_accuracy: 0.7644\n",
      "Epoch 28/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.5478 - sparse_categorical_accuracy: 0.7654\n",
      "Epoch 29/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.5469 - sparse_categorical_accuracy: 0.7667\n",
      "Epoch 30/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.5450 - sparse_categorical_accuracy: 0.7664\n",
      "Epoch 31/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.5456 - sparse_categorical_accuracy: 0.7662\n",
      "Epoch 32/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.5445 - sparse_categorical_accuracy: 0.7667\n",
      "Epoch 33/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.5444 - sparse_categorical_accuracy: 0.7664\n",
      "Epoch 34/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.5437 - sparse_categorical_accuracy: 0.7673\n",
      "Epoch 35/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.5414 - sparse_categorical_accuracy: 0.7684\n",
      "Epoch 36/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.5414 - sparse_categorical_accuracy: 0.7682\n",
      "Epoch 37/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.5406 - sparse_categorical_accuracy: 0.7688\n",
      "Epoch 38/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.5417 - sparse_categorical_accuracy: 0.7678\n",
      "Epoch 39/50\n",
      "1864/1864 [==============================] - 12s 6ms/step - loss: 0.5392 - sparse_categorical_accuracy: 0.7696\n",
      "Epoch 40/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.5386 - sparse_categorical_accuracy: 0.7687\n",
      "Epoch 41/50\n",
      "1864/1864 [==============================] - 12s 6ms/step - loss: 0.5393 - sparse_categorical_accuracy: 0.7695\n",
      "Epoch 42/50\n",
      "1864/1864 [==============================] - 12s 6ms/step - loss: 0.5373 - sparse_categorical_accuracy: 0.7700\n",
      "Epoch 43/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.5367 - sparse_categorical_accuracy: 0.7703\n",
      "Epoch 44/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.5369 - sparse_categorical_accuracy: 0.7697\n",
      "Epoch 45/50\n",
      "1864/1864 [==============================] - 12s 6ms/step - loss: 0.5353 - sparse_categorical_accuracy: 0.7708\n",
      "Epoch 46/50\n",
      "1864/1864 [==============================] - 12s 6ms/step - loss: 0.5361 - sparse_categorical_accuracy: 0.7709\n",
      "Epoch 47/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.5349 - sparse_categorical_accuracy: 0.7712\n",
      "Epoch 48/50\n",
      "1864/1864 [==============================] - 12s 6ms/step - loss: 0.5340 - sparse_categorical_accuracy: 0.7717\n",
      "Epoch 49/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.5332 - sparse_categorical_accuracy: 0.7722\n",
      "Epoch 50/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.5339 - sparse_categorical_accuracy: 0.7711\n",
      "Model training finished\n",
      "Test accuracy: 76.78%\n"
     ]
    }
   ],
   "source": [
    "run_experiment(baseline_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2: Wide & Deep model\n",
    "In the second experiment, we create a Wide & Deep model. The wide part of the model a linear model, while the deep part of the model is a multi-layer feed-forward network.\n",
    "\n",
    "Use the sparse representation of the input features in the wide part of the model and the dense representation of the input features for the deep part of the model.\n",
    "\n",
    "Note that every input features contributes to both parts of the model with different representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "def create_wide_and_deep_model():\n",
    "\n",
    "    inputs = create_model_inputs()\n",
    "    wide = encode_inputs(inputs)\n",
    "    wide = layers.BatchNormalization()(wide)\n",
    "\n",
    "    deep = encode_inputs(inputs, use_embedding=True)\n",
    "    for units in hidden_units:\n",
    "        deep = layers.Dense(units)(deep)\n",
    "        deep = layers.BatchNormalization()(deep)\n",
    "        deep = layers.ReLU()(deep)\n",
    "        deep = layers.Dropout(dropout_rate)(deep)\n",
    "\n",
    "    merged = layers.concatenate([wide, deep])\n",
    "    outputs = layers.Dense(units=NUM_CLASSES, activation=\"softmax\")(merged)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "wide_and_deep_model = create_wide_and_deep_model()\n",
    "keras.utils.plot_model(wide_and_deep_model, show_shapes=True, rankdir=\"LR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training the model...\n",
      "Epoch 1/50\n",
      "1864/1864 [==============================] - 24s 12ms/step - loss: 0.9264 - sparse_categorical_accuracy: 0.6378\n",
      "Epoch 2/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.6126 - sparse_categorical_accuracy: 0.7330\n",
      "Epoch 3/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.5911 - sparse_categorical_accuracy: 0.7415\n",
      "Epoch 4/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.5781 - sparse_categorical_accuracy: 0.7472\n",
      "Epoch 5/50\n",
      "1864/1864 [==============================] - 10s 6ms/step - loss: 0.5680 - sparse_categorical_accuracy: 0.7511\n",
      "Epoch 6/50\n",
      "1864/1864 [==============================] - 10s 6ms/step - loss: 0.5592 - sparse_categorical_accuracy: 0.7553\n",
      "Epoch 7/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.5522 - sparse_categorical_accuracy: 0.7579\n",
      "Epoch 8/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.5478 - sparse_categorical_accuracy: 0.7611\n",
      "Epoch 9/50\n",
      "1864/1864 [==============================] - 10s 6ms/step - loss: 0.5435 - sparse_categorical_accuracy: 0.7636\n",
      "Epoch 10/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.5391 - sparse_categorical_accuracy: 0.7656\n",
      "Epoch 11/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.5376 - sparse_categorical_accuracy: 0.7660\n",
      "Epoch 12/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.5337 - sparse_categorical_accuracy: 0.7684\n",
      "Epoch 13/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.5311 - sparse_categorical_accuracy: 0.7695\n",
      "Epoch 14/50\n",
      "1864/1864 [==============================] - 10s 5ms/step - loss: 0.5294 - sparse_categorical_accuracy: 0.7707\n",
      "Epoch 15/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.5279 - sparse_categorical_accuracy: 0.7717\n",
      "Epoch 16/50\n",
      "1864/1864 [==============================] - 10s 6ms/step - loss: 0.5261 - sparse_categorical_accuracy: 0.7722\n",
      "Epoch 17/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.5231 - sparse_categorical_accuracy: 0.7742\n",
      "Epoch 18/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.5217 - sparse_categorical_accuracy: 0.7754\n",
      "Epoch 19/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.5200 - sparse_categorical_accuracy: 0.7759\n",
      "Epoch 20/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.5192 - sparse_categorical_accuracy: 0.7768\n",
      "Epoch 21/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.5166 - sparse_categorical_accuracy: 0.7777\n",
      "Epoch 22/50\n",
      "1864/1864 [==============================] - 10s 6ms/step - loss: 0.5165 - sparse_categorical_accuracy: 0.7779\n",
      "Epoch 23/50\n",
      "1864/1864 [==============================] - 10s 6ms/step - loss: 0.5143 - sparse_categorical_accuracy: 0.7793\n",
      "Epoch 24/50\n",
      "1864/1864 [==============================] - 10s 6ms/step - loss: 0.5122 - sparse_categorical_accuracy: 0.7800\n",
      "Epoch 25/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.5111 - sparse_categorical_accuracy: 0.7813\n",
      "Epoch 26/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.5101 - sparse_categorical_accuracy: 0.7811\n",
      "Epoch 27/50\n",
      "1864/1864 [==============================] - 10s 6ms/step - loss: 0.5091 - sparse_categorical_accuracy: 0.7821\n",
      "Epoch 28/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.5089 - sparse_categorical_accuracy: 0.7816\n",
      "Epoch 29/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.5069 - sparse_categorical_accuracy: 0.7825\n",
      "Epoch 30/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.5065 - sparse_categorical_accuracy: 0.7825\n",
      "Epoch 31/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.5070 - sparse_categorical_accuracy: 0.7820\n",
      "Epoch 32/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.5050 - sparse_categorical_accuracy: 0.7834\n",
      "Epoch 33/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.5051 - sparse_categorical_accuracy: 0.7837\n",
      "Epoch 34/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.5033 - sparse_categorical_accuracy: 0.7838\n",
      "Epoch 35/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.5032 - sparse_categorical_accuracy: 0.7839\n",
      "Epoch 36/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.5025 - sparse_categorical_accuracy: 0.7835\n",
      "Epoch 37/50\n",
      "1864/1864 [==============================] - 10s 6ms/step - loss: 0.5024 - sparse_categorical_accuracy: 0.7845\n",
      "Epoch 38/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.5015 - sparse_categorical_accuracy: 0.7846\n",
      "Epoch 39/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.5008 - sparse_categorical_accuracy: 0.7863\n",
      "Epoch 40/50\n",
      "1864/1864 [==============================] - 10s 6ms/step - loss: 0.5006 - sparse_categorical_accuracy: 0.7856\n",
      "Epoch 41/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.4997 - sparse_categorical_accuracy: 0.7857\n",
      "Epoch 42/50\n",
      "1864/1864 [==============================] - 10s 6ms/step - loss: 0.4998 - sparse_categorical_accuracy: 0.7863\n",
      "Epoch 43/50\n",
      "1864/1864 [==============================] - 10s 6ms/step - loss: 0.4983 - sparse_categorical_accuracy: 0.7867\n",
      "Epoch 44/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.4991 - sparse_categorical_accuracy: 0.7857\n",
      "Epoch 45/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.4970 - sparse_categorical_accuracy: 0.7872\n",
      "Epoch 46/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.4963 - sparse_categorical_accuracy: 0.7873\n",
      "Epoch 47/50\n",
      "1864/1864 [==============================] - 10s 6ms/step - loss: 0.4964 - sparse_categorical_accuracy: 0.7866\n",
      "Epoch 48/50\n",
      "1864/1864 [==============================] - 10s 6ms/step - loss: 0.4965 - sparse_categorical_accuracy: 0.7877\n",
      "Epoch 49/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.4946 - sparse_categorical_accuracy: 0.7881\n",
      "Epoch 50/50\n",
      "1864/1864 [==============================] - 10s 5ms/step - loss: 0.4950 - sparse_categorical_accuracy: 0.7877\n",
      "Model training finished\n",
      "Test accuracy: 80.92%\n"
     ]
    }
   ],
   "source": [
    "run_experiment(wide_and_deep_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 3: Deep & Cross model\n",
    "In the third experiment, we create a Deep & Cross model. The deep part of this model is the same as the deep part created in the previous experiment. The key idea of the cross part is to apply explicit feature crossing in an efficient way, where the degree of cross features grows with layer depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "def create_deep_and_cross_model():\n",
    "\n",
    "    inputs = create_model_inputs()\n",
    "    x0 = encode_inputs(inputs, use_embedding=True)\n",
    "\n",
    "    cross = x0\n",
    "    for _ in hidden_units:\n",
    "        units = cross.shape[-1]\n",
    "        x = layers.Dense(units)(cross)\n",
    "        cross = x0 * x + cross\n",
    "    cross = layers.BatchNormalization()(cross)\n",
    "\n",
    "    deep = x0\n",
    "    for units in hidden_units:\n",
    "        deep = layers.Dense(units)(deep)\n",
    "        deep = layers.BatchNormalization()(deep)\n",
    "        deep = layers.ReLU()(deep)\n",
    "        deep = layers.Dropout(dropout_rate)(deep)\n",
    "\n",
    "    merged = layers.concatenate([cross, deep])\n",
    "    outputs = layers.Dense(units=NUM_CLASSES, activation=\"softmax\")(merged)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "deep_and_cross_model = create_deep_and_cross_model()\n",
    "keras.utils.plot_model(deep_and_cross_model, show_shapes=True, rankdir=\"LR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training the model...\n",
      "Epoch 1/50\n",
      "1864/1864 [==============================] - 24s 12ms/step - loss: 0.8968 - sparse_categorical_accuracy: 0.6485\n",
      "Epoch 2/50\n",
      "1864/1864 [==============================] - 12s 6ms/step - loss: 0.6005 - sparse_categorical_accuracy: 0.7404\n",
      "Epoch 3/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.5764 - sparse_categorical_accuracy: 0.7511\n",
      "Epoch 4/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.5636 - sparse_categorical_accuracy: 0.7562\n",
      "Epoch 5/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.5559 - sparse_categorical_accuracy: 0.7589\n",
      "Epoch 6/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.5488 - sparse_categorical_accuracy: 0.7629\n",
      "Epoch 7/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.5445 - sparse_categorical_accuracy: 0.7648\n",
      "Epoch 8/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.5408 - sparse_categorical_accuracy: 0.7666\n",
      "Epoch 9/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.5372 - sparse_categorical_accuracy: 0.7683\n",
      "Epoch 10/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.5338 - sparse_categorical_accuracy: 0.7702\n",
      "Epoch 11/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.5312 - sparse_categorical_accuracy: 0.7712\n",
      "Epoch 12/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.5287 - sparse_categorical_accuracy: 0.7729\n",
      "Epoch 13/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.5262 - sparse_categorical_accuracy: 0.7736\n",
      "Epoch 14/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.5235 - sparse_categorical_accuracy: 0.7745\n",
      "Epoch 15/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.5211 - sparse_categorical_accuracy: 0.7757\n",
      "Epoch 16/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.5195 - sparse_categorical_accuracy: 0.7769\n",
      "Epoch 17/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.5192 - sparse_categorical_accuracy: 0.7770\n",
      "Epoch 18/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.5174 - sparse_categorical_accuracy: 0.7779\n",
      "Epoch 19/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.5154 - sparse_categorical_accuracy: 0.7783\n",
      "Epoch 20/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.5147 - sparse_categorical_accuracy: 0.7787\n",
      "Epoch 21/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.5139 - sparse_categorical_accuracy: 0.7797\n",
      "Epoch 22/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.5122 - sparse_categorical_accuracy: 0.7800\n",
      "Epoch 23/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.5114 - sparse_categorical_accuracy: 0.7809\n",
      "Epoch 24/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.5099 - sparse_categorical_accuracy: 0.7806\n",
      "Epoch 25/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.5081 - sparse_categorical_accuracy: 0.7824\n",
      "Epoch 26/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.5068 - sparse_categorical_accuracy: 0.7826\n",
      "Epoch 27/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.5062 - sparse_categorical_accuracy: 0.7827\n",
      "Epoch 28/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.5056 - sparse_categorical_accuracy: 0.7830\n",
      "Epoch 29/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.5042 - sparse_categorical_accuracy: 0.7833\n",
      "Epoch 30/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.5031 - sparse_categorical_accuracy: 0.7839\n",
      "Epoch 31/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.5022 - sparse_categorical_accuracy: 0.7851\n",
      "Epoch 32/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.5010 - sparse_categorical_accuracy: 0.7858\n",
      "Epoch 33/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.5000 - sparse_categorical_accuracy: 0.7859\n",
      "Epoch 34/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.4988 - sparse_categorical_accuracy: 0.7870\n",
      "Epoch 35/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.4984 - sparse_categorical_accuracy: 0.7861\n",
      "Epoch 36/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.4969 - sparse_categorical_accuracy: 0.7876\n",
      "Epoch 37/50\n",
      "1864/1864 [==============================] - 10s 6ms/step - loss: 0.4967 - sparse_categorical_accuracy: 0.7874\n",
      "Epoch 38/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.4951 - sparse_categorical_accuracy: 0.7885\n",
      "Epoch 39/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.4952 - sparse_categorical_accuracy: 0.7881\n",
      "Epoch 40/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.4933 - sparse_categorical_accuracy: 0.7891\n",
      "Epoch 41/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.4932 - sparse_categorical_accuracy: 0.7889\n",
      "Epoch 42/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.4923 - sparse_categorical_accuracy: 0.7901\n",
      "Epoch 43/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.4920 - sparse_categorical_accuracy: 0.7892\n",
      "Epoch 44/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.4916 - sparse_categorical_accuracy: 0.7897\n",
      "Epoch 45/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.4898 - sparse_categorical_accuracy: 0.7902\n",
      "Epoch 46/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.4892 - sparse_categorical_accuracy: 0.7915\n",
      "Epoch 47/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.4897 - sparse_categorical_accuracy: 0.7913\n",
      "Epoch 48/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.4884 - sparse_categorical_accuracy: 0.7916\n",
      "Epoch 49/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.4872 - sparse_categorical_accuracy: 0.7922\n",
      "Epoch 50/50\n",
      "1864/1864 [==============================] - 11s 6ms/step - loss: 0.4868 - sparse_categorical_accuracy: 0.7919\n",
      "Model training finished\n",
      "Test accuracy: 80.61%\n"
     ]
    }
   ],
   "source": [
    "run_experiment(deep_and_cross_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "You can use Keras Preprocessing Layers to easily handle categorical features with different encoding mechanisms, including one-hot encoding and feature embedding. In addition, different model architectures — like wide, deep, and cross networks — have different advantages, with respect to different dataset properties. You can explore using them independently or combining them to achieve the best result for your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:studio]",
   "language": "python",
   "name": "conda-env-studio-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
